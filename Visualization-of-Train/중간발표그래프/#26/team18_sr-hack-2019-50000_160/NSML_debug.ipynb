{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2019-present NAVER Corp.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "def load_label(label_path):\n",
    "    char2index = dict() # [ch] = id\n",
    "    index2char = dict() # [id] = ch\n",
    "    with open(label_path, 'r') as f:\n",
    "        for no, line in enumerate(f):\n",
    "            if line[0] == '#': \n",
    "                continue\n",
    "\n",
    "            index, char, freq = line.strip().split('\\t')\n",
    "            char = char.strip()\n",
    "            if len(char) == 0:\n",
    "                char = ' '\n",
    "\n",
    "            char2index[char] = int(index)\n",
    "            index2char[int(index)] = char\n",
    "\n",
    "    return char2index, index2char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The wavio module defines the functions:\n",
    "read(file)\n",
    "    Read a WAV file and return a `wavio.Wav` object, with attributes\n",
    "    `data`, `rate` and `sampwidth`.\n",
    "write(filename, data, rate, scale=None, sampwidth=None)\n",
    "    Write a numpy array to a WAV file.\n",
    "-----\n",
    "Author: Warren Weckesser\n",
    "License: BSD 2-Clause:\n",
    "Copyright (c) 2015, Warren Weckesser\n",
    "All rights reserved.\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "1. Redistributions of source code must retain the above copyright notice,\n",
    "   this list of conditions and the following disclaimer.\n",
    "2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "   this list of conditions and the following disclaimer in the documentation\n",
    "   and/or other materials provided with the distribution.\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"\n",
    "\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _wav2array(nchannels, sampwidth, data):\n",
    "    \"\"\"data must be the string containing the bytes from the wav file.\"\"\"\n",
    "    num_samples, remainder = divmod(len(data), sampwidth * nchannels)\n",
    "    if remainder > 0:\n",
    "        raise ValueError('The length of data is not a multiple of '\n",
    "                         'sampwidth * num_channels.')\n",
    "    if sampwidth > 4:\n",
    "        raise ValueError(\"sampwidth must not be greater than 4.\")\n",
    "\n",
    "    if sampwidth == 3:\n",
    "        a = np.empty((num_samples, nchannels, 4), dtype=np.uint8)\n",
    "        raw_bytes = np.fromstring(data, dtype=np.uint8)\n",
    "        a[:, :, :sampwidth] = raw_bytes.reshape(-1, nchannels, sampwidth)\n",
    "        a[:, :, sampwidth:] = (a[:, :, sampwidth - 1:sampwidth] >> 7) * 255\n",
    "        result = a.view('<i4').reshape(a.shape[:-1])\n",
    "    else:\n",
    "        # 8 bit samples are stored as unsigned ints; others as signed ints.\n",
    "        dt_char = 'u' if sampwidth == 1 else 'i'\n",
    "        a = np.fromstring(data, dtype='<%s%d' % (dt_char, sampwidth))\n",
    "        result = a.reshape(-1, nchannels)\n",
    "    return result\n",
    "\n",
    "\n",
    "def readwav(file):\n",
    "    \"\"\"\n",
    "    Read a wav file.\n",
    "    Returns the frame rate, sample width (in bytes) and a numpy array\n",
    "    containing the data.\n",
    "    This function does not read compressed wav files.\n",
    "    \"\"\"\n",
    "    wav = wave.open(file)\n",
    "    rate = wav.getframerate()\n",
    "    nchannels = wav.getnchannels()\n",
    "    sampwidth = wav.getsampwidth()\n",
    "    nframes = wav.getnframes()\n",
    "    data = wav.readframes(nframes)\n",
    "    wav.close()\n",
    "    array = _wav2array(nchannels, sampwidth, data)\n",
    "    return rate, sampwidth, array\n",
    "\n",
    "\n",
    "def writewav24(filename, rate, data):\n",
    "    \"\"\"Create a 24 bit wav file.\n",
    "    data must be \"array-like\", either 1- or 2-dimensional.  If it is 2-d,\n",
    "    the rows are the frames (i.e. samples) and the columns are the channels.\n",
    "    The data is assumed to be signed, and the values are assumed to be\n",
    "    within the range of a 24 bit integer.  Floating point values are\n",
    "    converted to integers.  The data is not rescaled or normalized before\n",
    "    writing it to the file.\n",
    "    Example: Create a 3 second 440 Hz sine wave.\n",
    "    >>> rate = 22050  # samples per second\n",
    "    >>> T = 3         # sample duration (seconds)\n",
    "    >>> f = 440.0     # sound frequency (Hz)\n",
    "    >>> t = np.linspace(0, T, T*rate, endpoint=False)\n",
    "    >>> x = (2**23 - 1) * np.sin(2 * np.pi * f * t)\n",
    "    >>> writewav24(\"sine24.wav\", rate, x)\n",
    "    \"\"\"\n",
    "    a32 = np.asarray(data, dtype=np.int32)\n",
    "    if a32.ndim == 1:\n",
    "        # Convert to a 2D array with a single column.\n",
    "        a32.shape = a32.shape + (1,)\n",
    "    # By shifting first 0 bits, then 8, then 16, the resulting output\n",
    "    # is 24 bit little-endian.\n",
    "    a8 = (a32.reshape(a32.shape + (1,)) >> np.array([0, 8, 16])) & 255\n",
    "    wavdata = a8.astype(np.uint8).tostring()\n",
    "\n",
    "    w = wave.open(filename, 'wb')\n",
    "    w.setnchannels(a32.shape[1])\n",
    "    w.setsampwidth(3)\n",
    "    w.setframerate(rate)\n",
    "    w.writeframes(wavdata)\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2019-present NAVER Corp.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import threading\n",
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "logger = logging.getLogger('root')\n",
    "FORMAT = \"[%(asctime)s %(filename)s:%(lineno)s - %(funcName)s()] %(message)s\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, format=FORMAT)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "PAD = 0\n",
    "N_FFT = 512\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "target_dict = dict()\n",
    "\n",
    "def load_targets(path):\n",
    "    with open(path, 'r') as f:\n",
    "        for no, line in enumerate(f):\n",
    "            key, target = line.strip().split(',')\n",
    "            target_dict[key] = target\n",
    "\n",
    "# 수정할 것 1\n",
    "# Mel-Spectrogram으로 만듭시다\n",
    "\n",
    "def get_spectrogram_feature(filepath):\n",
    "    (rate, width, sig) = wavio.readwav(filepath)\n",
    "    sig = sig.ravel()\n",
    "\n",
    "    stft = torch.stft(torch.FloatTensor(sig),\n",
    "                        N_FFT,\n",
    "                        hop_length=int(0.01*SAMPLE_RATE),\n",
    "                        win_length=int(0.030*SAMPLE_RATE),\n",
    "                        window=torch.hamming_window(int(0.030*SAMPLE_RATE)),\n",
    "                        center=False,\n",
    "                        normalized=False,\n",
    "                        onesided=True)\n",
    "\n",
    "    stft = (stft[:,:,0].pow(2) + stft[:,:,1].pow(2)).pow(0.5);\n",
    "    amag = stft.numpy();\n",
    "    feat = torch.FloatTensor(amag)\n",
    "    feat = torch.FloatTensor(feat).transpose(0, 1)\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _normalize(S):\n",
    "    min_level_db = -100\n",
    "    return np.clip((S - min_level_db) / -min_level_db, 0 ,1)\n",
    "\n",
    "\n",
    "def _zero_padding(ndarray, max_m, max_n):\n",
    "    zeros = np.zeros( ((max_m), max_n - len(ndarray[0])) )\n",
    "    ndarray = np.append(ndarray, zeros, axis = 1)\n",
    "    return ndarray\n",
    "'''\n",
    "'''\n",
    "# Mel-Spectrogram으로 테스트\n",
    "def get_melspectrogram_feature(filepath):\n",
    "    y, sr = librosa.load(filepath)\n",
    "    wav_S = librosa.feature.melspectrogram(y = y, sr = sr, n_mels = 128)\n",
    "    log_wav_S = librosa.power_to_db(wav_S, np.max)\n",
    "    norm_S = _normalize(log_wav_S)\n",
    "    feat = np.array(norm_S)\n",
    "    #logger.info('{:4d} {:4d}'.format(len(norm_S), len(norm_S[0])))\n",
    "    feat = torch.FloatTensor(feat)\n",
    "    feat = torch.FloatTensor(feat).transpose(0, 1)\n",
    "    #logger.info('{:4d} {:4d}'.format(len(feat), len(feat[0])))\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "def get_script(filepath, bos_id, eos_id):\n",
    "    key = filepath.split('/')[-1].split('.')[0]\n",
    "    script = target_dict[key]\n",
    "    tokens = script.split(' ')\n",
    "    result = list()\n",
    "    result.append(bos_id)\n",
    "    for i in range(len(tokens)):\n",
    "        if len(tokens[i]) > 0:\n",
    "            result.append(int(tokens[i]))\n",
    "    result.append(eos_id)\n",
    "    return result\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, wav_paths, script_paths, bos_id=1307, eos_id=1308):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.script_paths = script_paths\n",
    "        self.bos_id, self.eos_id = bos_id, eos_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_paths)\n",
    "\n",
    "    def count(self):\n",
    "        return len(self.wav_paths)\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        feat = get_spectrogram_feature(self.wav_paths[idx])\n",
    "        logger.info('{:4d} {:4d}'.format(len(feat), len(feat[0])))\n",
    "        script = get_script(self.script_paths[idx], self.bos_id, self.eos_id)\n",
    "        return feat, script\n",
    "\n",
    "def _collate_fn(batch):\n",
    "    def seq_length_(p):\n",
    "        return len(p[0])\n",
    "\n",
    "    def target_length_(p):\n",
    "        return len(p[1])\n",
    "\n",
    "    seq_lengths = [len(s[0]) for s in batch]\n",
    "    target_lengths = [len(s[1]) for s in batch]\n",
    "\n",
    "    max_seq_sample = max(batch, key=seq_length_)[0]\n",
    "    max_target_sample = max(batch, key=target_length_)[1]\n",
    "\n",
    "    max_seq_size = max_seq_sample.size(0)\n",
    "    max_target_size = len(max_target_sample)\n",
    "\n",
    "    feat_size = max_seq_sample.size(1)\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    seqs = torch.zeros(batch_size, max_seq_size, feat_size)\n",
    "\n",
    "    targets = torch.zeros(batch_size, max_target_size).to(torch.long)\n",
    "    targets.fill_(PAD)\n",
    "\n",
    "    for x in range(batch_size):\n",
    "        sample = batch[x]\n",
    "        tensor = sample[0]\n",
    "        target = sample[1]\n",
    "        seq_length = tensor.size(0)\n",
    "        seqs[x].narrow(0, 0, seq_length).copy_(tensor)\n",
    "        targets[x].narrow(0, 0, len(target)).copy_(torch.LongTensor(target))\n",
    "\n",
    "    return seqs, targets, seq_lengths, target_lengths\n",
    "\n",
    "class BaseDataLoader(threading.Thread):\n",
    "    def __init__(self, dataset, queue, batch_size, thread_id):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.collate_fn = _collate_fn\n",
    "        self.dataset = dataset\n",
    "        self.queue = queue\n",
    "        self.index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_count = dataset.count()\n",
    "        self.thread_id = thread_id\n",
    "\n",
    "    def count(self):\n",
    "        return math.ceil(self.dataset_count / self.batch_size)\n",
    "\n",
    "    def create_empty_batch(self):\n",
    "        seqs = torch.zeros(0, 0, 0)\n",
    "        targets = torch.zeros(0, 0).to(torch.long)\n",
    "        seq_lengths = list()\n",
    "        target_lengths = list()\n",
    "        return seqs, targets, seq_lengths, target_lengths\n",
    "\n",
    "    def run(self):\n",
    "        logger.debug('loader %d start' % (self.thread_id))\n",
    "        while True:\n",
    "            items = list()\n",
    "\n",
    "            for i in range(self.batch_size): \n",
    "                if self.index >= self.dataset_count:\n",
    "                    break\n",
    "\n",
    "                items.append(self.dataset.getitem(self.index))\n",
    "                self.index += 1\n",
    "\n",
    "            if len(items) == 0:\n",
    "                batch = self.create_empty_batch()\n",
    "                self.queue.put(batch)\n",
    "                break\n",
    "\n",
    "            random.shuffle(items)\n",
    "\n",
    "            batch = self.collate_fn(items)\n",
    "            self.queue.put(batch)\n",
    "        logger.debug('loader %d stop' % (self.thread_id))\n",
    "\n",
    "class MultiLoader():\n",
    "    def __init__(self, dataset_list, queue, batch_size, worker_size):\n",
    "        self.dataset_list = dataset_list\n",
    "        self.queue = queue\n",
    "        self.batch_size = batch_size\n",
    "        self.worker_size = worker_size\n",
    "        self.loader = list()\n",
    "\n",
    "        for i in range(self.worker_size):\n",
    "            self.loader.append(BaseDataLoader(self.dataset_list[i], self.queue, self.batch_size, i))\n",
    "\n",
    "    def start(self):\n",
    "        for i in range(self.worker_size):\n",
    "            self.loader[i].start()\n",
    "\n",
    "    def join(self):\n",
    "        for i in range(self.worker_size):\n",
    "            self.loader[i].join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([78, 257])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spectrogram_feature('marvin (1).wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_melspectrogram_feature('marvin (1).wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([97, 257])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spectrogram_feature('cat (1).wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_melspectrogram_feature('cat (1).wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 0\n",
    "wav_paths = 'C:\\Users\\SooHwanKim\\Desktop\\수환\\학교\\예비캡스톤\\소스코드\\테스트\\dataset'\n",
    "workers = 4\n",
    "batch_size = 8\n",
    "\n",
    "def split_dataset(wav_paths, script_paths, valid_ratio=0.05):\n",
    "    train_loader_count = workers\n",
    "    records_num = len(wav_paths)\n",
    "    batch_num = math.ceil(records_num / batch_size)\n",
    "\n",
    "    valid_batch_num = math.ceil(batch_num * valid_ratio)\n",
    "    train_batch_num = batch_num - valid_batch_num\n",
    "\n",
    "    batch_num_per_train_loader = math.ceil(train_batch_num / workers)\n",
    "\n",
    "    train_begin = 0\n",
    "    train_end_raw_id = 0\n",
    "    train_dataset_list = list()\n",
    "\n",
    "    for i in range(config.workers):\n",
    "\n",
    "        train_end = min(train_begin + batch_num_per_train_loader, train_batch_num)\n",
    "\n",
    "        train_begin_raw_id = train_begin * batch_size\n",
    "        train_end_raw_id = train_end * batch_size\n",
    "\n",
    "        train_dataset_list.append(BaseDataset(\n",
    "                                        wav_paths[train_begin_raw_id:train_end_raw_id],\n",
    "                                        script_paths[train_begin_raw_id:train_end_raw_id],\n",
    "                                        SOS_token, EOS_token))\n",
    "        train_begin = train_end \n",
    "\n",
    "    valid_dataset = BaseDataset(wav_paths[train_end_raw_id:], script_paths[train_end_raw_id:], SOS_token, EOS_token)\n",
    "\n",
    "    return train_batch_num, train_dataset_list, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97, 257])\n",
      "tensor([[5.0011e+02, 8.4333e+02, 5.4157e+02,  ..., 2.7685e+00, 3.5773e+00,\n",
      "         3.5385e-02],\n",
      "        [2.1543e+02, 5.3764e+02, 9.8892e+02,  ..., 2.5724e+00, 1.6558e+00,\n",
      "         1.5334e+00],\n",
      "        [4.8812e+02, 4.5325e+02, 1.8081e+03,  ..., 2.8591e+00, 4.9504e+00,\n",
      "         7.7795e-01],\n",
      "        ...,\n",
      "        [1.0760e+02, 1.6529e+03, 1.8535e+03,  ..., 2.5241e+00, 2.2961e+00,\n",
      "         2.8644e+00],\n",
      "        [1.1281e+03, 1.4562e+03, 1.5999e+03,  ..., 1.6011e+00, 1.2807e+00,\n",
      "         2.3992e+00],\n",
      "        [1.4431e+02, 5.4400e+02, 8.0558e+02,  ..., 4.5966e+00, 2.4539e+00,\n",
      "         9.9558e-01]])\n",
      "torch.Size([44, 257])\n",
      "tensor([[0.6179, 0.6400, 0.6618,  ..., 0.2000, 0.2000, 0.2000],\n",
      "        [0.5692, 0.5803, 0.6016,  ..., 0.2000, 0.2000, 0.2000],\n",
      "        [0.5250, 0.5500, 0.5527,  ..., 0.2000, 0.2000, 0.2000],\n",
      "        ...,\n",
      "        [0.4954, 0.5519, 0.5805,  ..., 0.2000, 0.2000, 0.2000],\n",
      "        [0.5219, 0.5745, 0.5715,  ..., 0.2000, 0.2000, 0.2000],\n",
      "        [0.5938, 0.5954, 0.5602,  ..., 0.2000, 0.2000, 0.2000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "PAD = 0\n",
    "N_FFT = 512\n",
    "SAMPLE_RATE = 16000\n",
    "def get_spectrogram_feature(filepath):\n",
    "    (rate, width, sig) = readwav(filepath)\n",
    "    #print(type(sig))\n",
    "    sig = sig.ravel()\n",
    "    #print(sig)\n",
    "    stft = torch.stft(torch.FloatTensor(sig),\n",
    "                        N_FFT,\n",
    "                        hop_length=int(0.01*SAMPLE_RATE),\n",
    "                        win_length=int(0.030*SAMPLE_RATE),\n",
    "                        window=torch.hamming_window(int(0.030*SAMPLE_RATE)),\n",
    "                        center=False,\n",
    "                        normalized=False,\n",
    "                        onesided=True)\n",
    "    stft = (stft[:,:,0].pow(2) + stft[:,:,1].pow(2)).pow(0.5);\n",
    "    amag = stft.numpy();\n",
    "    feat = torch.FloatTensor(amag)\n",
    "    feat = torch.FloatTensor(feat).transpose(0, 1)\n",
    "    print(feat.shape)\n",
    "    return feat\n",
    "\n",
    "def _normalize(S):\n",
    "    min_level_db = -100\n",
    "    return np.clip((S - min_level_db) / -min_level_db, 0 ,1)\n",
    "\n",
    "# Mel-Spectrogram으로 테스트\n",
    "def get_melspectrogram_feature(filepath):\n",
    "    y, sr = librosa.load(filepath)\n",
    "    wav_S = librosa.feature.melspectrogram(y = y, sr = sr, n_mels = 257)\n",
    "    log_wav_S = librosa.power_to_db(wav_S, np.max)\n",
    "    norm_S = _normalize(log_wav_S)\n",
    "    feat = np.array(norm_S)\n",
    "    #logger.info('{:4d} {:4d}'.format(len(norm_S), len(norm_S[0])))\n",
    "    feat = torch.FloatTensor(feat)\n",
    "    feat = torch.FloatTensor(feat).transpose(0, 1)\n",
    "    #logger.info('{:4d} {:4d}'.format(len(feat), len(feat[0])))\n",
    "    print(feat.shape)\n",
    "    return feat\n",
    "\n",
    "print(get_spectrogram_feature('C:/Users/SooHwanKim/Desktop/수환/학교/예비캡스톤/소스코드/테스트/dataset/bed/bed (1).wav'))\n",
    "print(get_melspectrogram_feature('C:/Users/SooHwanKim/Desktop/수환/학교/예비캡스톤/소스코드/테스트/dataset/bed/bed (1).wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = queue.Queue(4*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<queue.Queue object at 0x000001B5625BD208>\n"
     ]
    }
   ],
   "source": [
    "print(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.put(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, wav_paths, script_paths, bos_id=1307, eos_id=1308):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.script_paths = script_paths\n",
    "        self.bos_id, self.eos_id = bos_id, eos_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_paths)\n",
    "\n",
    "    def count(self):\n",
    "        return len(self.wav_paths)\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        feat = get_spectrogram_feature(self.wav_paths[idx])\n",
    "        logger.info('{:4d} {:4d}'.format(len(feat), len(feat[0])))\n",
    "        script = get_script(self.script_paths[idx], self.bos_id, self.eos_id)\n",
    "        logger.info('script도 잘 됨')\n",
    "        return feat, script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "q = queue.Queue(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<queue.Queue object at 0x000001B562618518>\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.put(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

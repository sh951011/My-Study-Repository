{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                  #  신경망 모델들이 포함\n",
    "import torch.optim as optim            #  경사하강법 알고리즘\n",
    "import torch.nn.init as init           #  텐서에 초깃값을 주기 위해 필요한 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000  #  횟수를 num_data와 num_epoch라는 변수에 저장\n",
    "num_epoch = 500  #  횟수를 num_data와 num_epoch라는 변수에 저장\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10) # x라는 변수에 [num_data, 1] 모양의 텐서를 생성하는데 \n",
    "                                                      #  이 텐서의 값들을 init.uniform_()이라는 함수로 균등하게 초기화함\n",
    "    \n",
    "# y에 노이즈를 추가하기 위해 y_noise라는 변수를 만듦\n",
    "# 데이터에 어떠한 관계가 존재한다고 해도 보통 센서나 관측을 통해 들어오는 데이터는\n",
    "# 노이즈가 추가된 상태로 들어오는 경우가 대부분이기 때문\n",
    "# 즉, 현실성을 반영하기 위해 노이즈를 추가한 것\n",
    "# 노이즈는 표준정규분포를 따르는 노이즈를 사용하며, 이를 가우시안 노이즈라고 한다\n",
    "    \n",
    "#  init.normal_() 함수를 통해 초기화. \n",
    "#  mean 은 default인 0을 쓰고, std (표준편차) 는 1로 지정\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1 ), std = 1)  \n",
    "\n",
    "#  y = 2x + 3\n",
    "y = 2*x + 3\n",
    "#  noise를 추가한 y => 결국은 label\n",
    "y_noise = 2*(x + noise) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)  #  선형회귀\n",
    "loss_func = nn.L1Loss()    #  L1손실 => 차이의 절댓값의 평균 => 평균제곱오차가 아닌 절댓값으로 한 것!!\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)  #  SGD : Stochastic gradient descent, lr (alpha) == 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.9348)\n",
      "0.09320496022701263 -0.6104046106338501\n",
      "0.13930077850818634 -0.608504593372345\n",
      "0.18529553711414337 -0.6065645813941956\n",
      "0.23119878768920898 -0.6045845746994019\n",
      "0.2769636809825897 -0.6025645732879639\n",
      "0.322481632232666 -0.6004645824432373\n",
      "0.3679368495941162 -0.5983245968818665\n",
      "0.41319572925567627 -0.5961245894432068\n",
      "0.4583468735218048 -0.5939046144485474\n",
      "0.5031793117523193 -0.5915846228599548\n",
      "tensor(7.8532)\n",
      "0.5478746294975281 -0.589224636554718\n",
      "0.5924756526947021 -0.5868446230888367\n",
      "0.6369175910949707 -0.584424614906311\n",
      "0.6811028718948364 -0.5819445848464966\n",
      "0.7248406410217285 -0.5793445706367493\n",
      "0.7682647705078125 -0.5766245722770691\n",
      "0.8112070560455322 -0.5737645626068115\n",
      "0.8536047339439392 -0.5707645416259766\n",
      "0.8953019380569458 -0.5676045417785645\n",
      "0.9363924860954285 -0.564304530620575\n",
      "tensor(5.9748)\n",
      "0.9771259427070618 -0.5609245300292969\n",
      "1.0172086954116821 -0.5574045181274414\n",
      "1.056426763534546 -0.5537045001983643\n",
      "1.0944620370864868 -0.5497444868087769\n",
      "1.1316457986831665 -0.5456644892692566\n",
      "1.1680052280426025 -0.5414444804191589\n",
      "1.2038440704345703 -0.5371044874191284\n",
      "1.2379026412963867 -0.5324844717979431\n",
      "1.2708314657211304 -0.5276444554328918\n",
      "1.3022432327270508 -0.5225444436073303\n",
      "tensor(4.6287)\n",
      "1.3318476676940918 -0.51710444688797\n",
      "1.3603625297546387 -0.5114644765853882\n",
      "1.3880794048309326 -0.505684494972229\n",
      "1.4147124290466309 -0.49972450733184814\n",
      "1.4392609596252441 -0.49350449442863464\n",
      "1.4628301858901978 -0.4871644973754883\n",
      "1.4849932193756104 -0.48060449957847595\n",
      "1.5068199634552002 -0.4739845097064972\n",
      "1.5271363258361816 -0.46718451380729675\n",
      "1.5464318990707397 -0.4602245092391968\n",
      "tensor(3.9950)\n",
      "1.5645320415496826 -0.45310449600219727\n",
      "1.5820136070251465 -0.44594448804855347\n",
      "1.5987701416015625 -0.4386644959449768\n",
      "1.6144132614135742 -0.4312244951725006\n",
      "1.6293915510177612 -0.42366448044776917\n",
      "1.64385986328125 -0.41606447100639343\n",
      "1.6573314666748047 -0.4083244800567627\n",
      "1.6697416305541992 -0.4004244804382324\n",
      "1.6818293333053589 -0.39248448610305786\n",
      "1.6935335397720337 -0.384504497051239\n",
      "tensor(3.7213)\n",
      "1.704717755317688 -0.37646448612213135\n",
      "1.7153557538986206 -0.3683444857597351\n",
      "1.7255865335464478 -0.36016449332237244\n",
      "1.7350530624389648 -0.35188448429107666\n",
      "1.7435506582260132 -0.3435244858264923\n",
      "1.7518757581710815 -0.3351444900035858\n",
      "1.7599303722381592 -0.32672449946403503\n",
      "1.767561674118042 -0.3182845115661621\n",
      "1.7751929759979248 -0.3098445236682892\n",
      "1.7823724746704102 -0.30134451389312744\n",
      "tensor(3.5731)\n",
      "1.7892045974731445 -0.2928045094013214\n",
      "1.796036720275879 -0.2842645049095154\n",
      "1.8028688430786133 -0.27572450041770935\n",
      "1.809170126914978 -0.2671245038509369\n",
      "1.8154635429382324 -0.2585445046424866\n",
      "1.8217569589614868 -0.24996450543403625\n",
      "1.8279014825820923 -0.2413645088672638\n",
      "1.833417534828186 -0.23272450268268585\n",
      "1.8389335870742798 -0.2240844964981079\n",
      "1.8441816568374634 -0.21542449295520782\n",
      "tensor(3.4613)\n",
      "1.8490321636199951 -0.2067444920539856\n",
      "1.8538826704025269 -0.19806449115276337\n",
      "1.858465552330017 -0.18934449553489685\n",
      "1.862912654876709 -0.18064449727535248\n",
      "1.8671857118606567 -0.17192450165748596\n",
      "1.8714587688446045 -0.16320450603961945\n",
      "1.875335931777954 -0.1544245034456253\n",
      "1.8791465759277344 -0.1456644982099533\n",
      "1.8828562498092651 -0.13688449561595917\n",
      "1.886565923690796 -0.12810449302196503\n",
      "tensor(3.3672)\n",
      "1.8898588418960571 -0.11938448995351791\n",
      "1.8929904699325562 -0.11064448952674866\n",
      "1.8960633277893066 -0.10192448645830154\n",
      "1.898810863494873 -0.09320448338985443\n",
      "1.9015583992004395 -0.08448448032140732\n",
      "1.9043059349060059 -0.0757644772529602\n",
      "1.9070534706115723 -0.06704447418451309\n",
      "1.9096429347991943 -0.058304473757743835\n",
      "1.9120346307754517 -0.049544475972652435\n",
      "1.9143112897872925 -0.04082447662949562\n",
      "tensor(3.2835)\n",
      "1.91641366481781 -0.032084476202726364\n",
      "1.9184867143630981 -0.02336447685956955\n",
      "1.9205597639083862 -0.014644477516412735\n",
      "1.9226328134536743 -0.00592447817325592\n",
      "1.9245721101760864 0.0028155213221907616\n",
      "1.9265114068984985 0.011555520817637444\n",
      "1.9284507036209106 0.02029551938176155\n",
      "1.9303900003433228 0.029035519808530807\n",
      "1.932187795639038 0.037795521318912506\n",
      "1.9339855909347534 0.046555519104003906\n",
      "tensor(3.2032)\n",
      "1.9357833862304688 0.055315516889095306\n",
      "1.937581181526184 0.0640755146741867\n",
      "1.9392207860946655 0.07281551510095596\n",
      "1.9406626224517822 0.08157551288604736\n",
      "1.9421221017837524 0.09031551331281662\n",
      "1.9435815811157227 0.09905551373958588\n",
      "1.944952368736267 0.10777551680803299\n",
      "1.9463231563568115 0.1164955198764801\n",
      "1.9477572441101074 0.12519551813602448\n",
      "1.9491913318634033 0.13389551639556885\n",
      "tensor(3.1247)\n",
      "1.9506254196166992 0.14259551465511322\n",
      "1.9519375562667847 0.15127551555633545\n",
      "1.953050136566162 0.15993551909923553\n",
      "1.9541627168655396 0.16859552264213562\n",
      "1.955275297164917 0.1772555261850357\n",
      "1.9563878774642944 0.1859155297279358\n",
      "1.9575440883636475 0.19455553591251373\n",
      "1.9585753679275513 0.20317552983760834\n",
      "1.959606647491455 0.21179552376270294\n",
      "1.9604438543319702 0.2203955203294754\n",
      "tensor(3.0486)\n",
      "1.9612281322479248 0.22897551953792572\n",
      "1.9620124101638794 0.23755551874637604\n",
      "1.962796688079834 0.24613551795482635\n",
      "1.9634793996810913 0.25469550490379333\n",
      "1.9641621112823486 0.2632555067539215\n",
      "1.964844822883606 0.2718155086040497\n",
      "1.9653842449188232 0.2803555130958557\n",
      "1.9660651683807373 0.2888755202293396\n",
      "1.966879963874817 0.29737553000450134\n",
      "1.9676947593688965 0.3058755397796631\n",
      "tensor(2.9751)\n",
      "1.968664526939392 0.31433552503585815\n",
      "1.9694682359695435 0.3227755129337311\n",
      "1.9702719449996948 0.331215500831604\n",
      "1.9710756540298462 0.33965548872947693\n",
      "1.9718133211135864 0.3480754792690277\n",
      "1.9725509881973267 0.3564954698085785\n",
      "1.973288655281067 0.3649154603481293\n",
      "1.9738798141479492 0.3733154535293579\n",
      "1.9744709730148315 0.38171544671058655\n",
      "1.9750621318817139 0.3901154398918152\n",
      "tensor(2.9036)\n",
      "1.9756532907485962 0.3985154330730438\n",
      "1.9761691093444824 0.4068954288959503\n",
      "1.9767346382141113 0.41525542736053467\n",
      "1.9774086475372314 0.4235954284667969\n",
      "1.9780826568603516 0.4319354295730591\n",
      "1.9787566661834717 0.4402754306793213\n",
      "1.9794306755065918 0.4486154317855835\n",
      "1.980034351348877 0.45693543553352356\n",
      "1.980638027191162 0.4652554392814636\n",
      "1.9812417030334473 0.4735754430294037\n",
      "tensor(2.8335)\n",
      "1.9818453788757324 0.48189544677734375\n",
      "1.9822665452957153 0.49019545316696167\n",
      "1.9825496673583984 0.49847546219825745\n",
      "1.982831358909607 0.5067354440689087\n",
      "1.9833108186721802 0.5149754285812378\n",
      "1.9836851358413696 0.5231754183769226\n",
      "1.984059453010559 0.5313754081726074\n",
      "1.9844337701797485 0.5395753979682922\n",
      "1.984808087348938 0.547775387763977\n",
      "1.9851824045181274 0.5559753775596619\n",
      "tensor(2.7656)\n",
      "1.9854704141616821 0.5641353726387024\n",
      "1.9858769178390503 0.5722553730010986\n",
      "1.9862834215164185 0.5803753733634949\n",
      "1.9866899251937866 0.5884953737258911\n",
      "1.9870964288711548 0.5966153740882874\n",
      "1.9876024723052979 0.6046953797340393\n",
      "1.988108515739441 0.6127753853797913\n",
      "1.9887889623641968 0.6208353638648987\n",
      "1.989409327507019 0.6288753747940063\n",
      "1.9900648593902588 0.6368953585624695\n",
      "tensor(2.6999)\n",
      "1.9904286861419678 0.6448753476142883\n",
      "1.9907925128936768 0.6528553366661072\n",
      "1.9911563396453857 0.660835325717926\n",
      "1.9915201663970947 0.6688153147697449\n",
      "1.9917391538619995 0.676775336265564\n",
      "1.9918608665466309 0.6847153306007385\n",
      "1.992120385169983 0.6926353573799133\n",
      "1.992379903793335 0.7005553841590881\n",
      "1.9925395250320435 0.7084353566169739\n",
      "1.9926763772964478 0.7162953615188599\n",
      "tensor(2.6368)\n",
      "1.992813229560852 0.7241553664207458\n",
      "1.9929500818252563 0.7320153713226318\n",
      "1.9932482242584229 0.7398553490638733\n",
      "1.9935086965560913 0.747675359249115\n",
      "1.993649959564209 0.7554753422737122\n",
      "1.9940603971481323 0.763235330581665\n",
      "1.9945148229599 0.7709553241729736\n",
      "1.9949711561203003 0.7786553502082825\n",
      "1.9955554008483887 0.7863153219223022\n",
      "1.9960403442382812 0.7939553260803223\n",
      "tensor(2.5764)\n",
      "1.9963772296905518 0.8015753030776978\n",
      "1.9967683553695679 0.809155285358429\n",
      "1.997159481048584 0.8167352676391602\n",
      "1.9974143505096436 0.8242952823638916\n",
      "1.9978129863739014 0.8318153023719788\n",
      "1.9982116222381592 0.8393353223800659\n",
      "1.998610258102417 0.8468553423881531\n",
      "1.9990088939666748 0.8543753623962402\n",
      "1.9994075298309326 0.8618953824043274\n",
      "1.9998061656951904 0.8694154024124146\n",
      "tensor(2.5194)\n",
      "2.0002048015594482 0.8769354224205017\n",
      "2.000603437423706 0.8844554424285889\n",
      "2.0008175373077393 0.8919554352760315\n",
      "2.0010316371917725 0.8994554281234741\n",
      "2.001222610473633 0.906935453414917\n",
      "2.001413583755493 0.9144154787063599\n",
      "2.001556873321533 0.9218554496765137\n",
      "2.0019173622131348 0.9292554259300232\n",
      "2.0022778511047363 0.9366554021835327\n",
      "2.002638339996338 0.9440553784370422\n",
      "tensor(2.4636)\n",
      "2.0029988288879395 0.9514553546905518\n",
      "2.003213882446289 0.958815336227417\n",
      "2.003469944000244 0.9661553502082825\n",
      "2.0037050247192383 0.9734753370285034\n",
      "2.00388503074646 0.9807553291320801\n",
      "2.0040650367736816 0.9880353212356567\n",
      "2.0042450428009033 0.9953153133392334\n",
      "2.004225492477417 1.0025553703308105\n",
      "2.0039868354797363 1.0097553730010986\n",
      "2.0037481784820557 1.0169553756713867\n",
      "tensor(2.4105)\n",
      "2.003499746322632 1.0241353511810303\n",
      "2.003251314163208 1.0313153266906738\n",
      "2.003042221069336 1.0384752750396729\n",
      "2.002833127975464 1.0456352233886719\n",
      "2.002688407897949 1.0527552366256714\n",
      "2.0025436878204346 1.059875249862671\n",
      "2.00239896774292 1.0669952630996704\n",
      "2.0020928382873535 1.0740952491760254\n",
      "2.001786708831787 1.0811952352523804\n",
      "2.00136661529541 1.0882751941680908\n",
      "tensor(2.3596)\n",
      "2.000946521759033 1.0953551530838013\n",
      "2.0005264282226562 1.1024351119995117\n",
      "2.00015926361084 1.1094551086425781\n",
      "1.9999617338180542 1.1164350509643555\n",
      "1.9997642040252686 1.1234149932861328\n",
      "1.999566674232483 1.1303949356079102\n",
      "1.9995403289794922 1.1373149156570435\n",
      "1.9995139837265015 1.1442348957061768\n",
      "1.9996542930603027 1.1511348485946655\n",
      "1.9994874000549316 1.1579948663711548\n",
      "tensor(2.3110)\n",
      "1.9993205070495605 1.164854884147644\n",
      "1.9991133213043213 1.1716948747634888\n",
      "1.998906135559082 1.1785348653793335\n",
      "1.9985630512237549 1.1853548288345337\n",
      "1.9982199668884277 1.1921747922897339\n",
      "1.9978768825531006 1.198994755744934\n",
      "1.9975297451019287 1.2057948112487793\n",
      "1.9972167015075684 1.21257483959198\n",
      "1.996903657913208 1.2193548679351807\n",
      "1.996682047843933 1.2261148691177368\n",
      "tensor(2.2646)\n",
      "1.9966551065444946 1.232834815979004\n",
      "1.9966281652450562 1.239554762840271\n",
      "1.996819019317627 1.2462347745895386\n",
      "1.996917963027954 1.2528947591781616\n",
      "1.9970169067382812 1.2595547437667847\n",
      "1.9969263076782227 1.2661947011947632\n",
      "1.996538758277893 1.2727746963500977\n",
      "1.9961512088775635 1.2793546915054321\n",
      "1.995953917503357 1.2858946323394775\n",
      "1.9958890676498413 1.292414665222168\n",
      "tensor(2.2207)\n",
      "1.9958242177963257 1.2989346981048584\n",
      "1.9957098960876465 1.3054146766662598\n",
      "1.9955955743789673 1.3118946552276611\n",
      "1.9953677654266357 1.318354606628418\n",
      "1.9951399564743042 1.3248145580291748\n",
      "1.9949121475219727 1.3312745094299316\n",
      "1.9947447776794434 1.3377145528793335\n",
      "1.994577407836914 1.3441545963287354\n",
      "1.9945749044418335 1.3505746126174927\n",
      "1.994572401046753 1.35699462890625\n",
      "tensor(2.1790)\n",
      "1.9946612119674683 1.3633946180343628\n",
      "1.9947500228881836 1.3697946071624756\n",
      "1.9950082302093506 1.3761745691299438\n",
      "1.9954043626785278 1.3825346231460571\n",
      "1.995800495147705 1.3888946771621704\n",
      "1.9961966276168823 1.3952547311782837\n",
      "1.9965927600860596 1.401614785194397\n",
      "1.9970675706863403 1.4079548120498657\n",
      "1.9973477125167847 1.41427481174469\n",
      "1.9974230527877808 1.4205348491668701\n",
      "tensor(2.1385)\n",
      "1.9974983930587769 1.4267948865890503\n",
      "1.9975266456604004 1.433034896850586\n",
      "1.9975526332855225 1.439254879951477\n",
      "1.9974817037582397 1.4454548358917236\n",
      "1.997259497642517 1.4516348838806152\n",
      "1.9970372915267944 1.4578149318695068\n",
      "1.9967082738876343 1.463974952697754\n",
      "1.9963792562484741 1.470134973526001\n",
      "1.996147632598877 1.4762749671936035\n",
      "1.9957737922668457 1.4823750257492065\n",
      "tensor(2.1003)\n",
      "1.995294451713562 1.488455057144165\n",
      "1.9948151111602783 1.4945350885391235\n",
      "1.9945014715194702 1.5005950927734375\n",
      "1.994187831878662 1.5066550970077515\n",
      "1.994083285331726 1.5126750469207764\n",
      "1.99397873878479 1.5186949968338013\n",
      "1.9939565658569336 1.5246750116348267\n",
      "1.9940177202224731 1.5306349992752075\n",
      "1.994152307510376 1.5365749597549438\n",
      "1.9942868947982788 1.5425149202346802\n",
      "tensor(2.0641)\n",
      "1.9943629503250122 1.548414945602417\n",
      "1.9946781396865845 1.5542749166488647\n",
      "1.9949933290481567 1.5601348876953125\n",
      "1.995308518409729 1.5659948587417603\n",
      "1.9956237077713013 1.571854829788208\n",
      "1.9959388971328735 1.5777148008346558\n",
      "1.9962540864944458 1.5835747718811035\n",
      "1.996569275856018 1.5894347429275513\n",
      "1.9969048500061035 1.5952746868133545\n",
      "1.9973503351211548 1.6010947227478027\n",
      "tensor(2.0297)\n",
      "1.9975801706314087 1.6068546772003174\n",
      "1.9978100061416626 1.612614631652832\n",
      "1.9981484413146973 1.6183546781539917\n",
      "1.9984663724899292 1.6240746974945068\n",
      "1.9987843036651611 1.629794716835022\n",
      "1.9988772869110107 1.635474681854248\n",
      "1.9989702701568604 1.6411546468734741\n",
      "1.99906325340271 1.6468346118927002\n",
      "1.9990566968917847 1.6524946689605713\n",
      "1.9990501403808594 1.6581547260284424\n",
      "tensor(1.9972)\n",
      "1.9993512630462646 1.6637747287750244\n",
      "1.99965238571167 1.6693947315216064\n",
      "2.0001261234283447 1.674994707107544\n",
      "2.0005998611450195 1.6805946826934814\n",
      "2.001128911972046 1.6861547231674194\n",
      "2.001519203186035 1.691694736480713\n",
      "2.00174617767334 1.6972147226333618\n",
      "2.0017223358154297 1.7026947736740112\n",
      "2.001554012298584 1.7081547975540161\n",
      "2.00173282623291 1.713574767112732\n",
      "tensor(1.9664)\n",
      "2.0019116401672363 1.7189947366714478\n",
      "2.0020573139190674 1.724394679069519\n",
      "2.0020289421081543 1.7297346591949463\n",
      "2.002000570297241 1.7350746393203735\n",
      "2.001972198486328 1.7404146194458008\n",
      "2.001943826675415 1.745754599571228\n",
      "2.0015807151794434 1.7510546445846558\n",
      "2.0013091564178467 1.75629460811615\n",
      "2.001124858856201 1.7614946365356445\n",
      "2.0008187294006348 1.7666746377944946\n",
      "tensor(1.9382)\n",
      "2.0005125999450684 1.7718546390533447\n",
      "2.000351905822754 1.7770146131515503\n",
      "2.0003738403320312 1.7821545600891113\n",
      "2.000549793243408 1.7872745990753174\n",
      "2.0004847049713135 1.7923545837402344\n",
      "2.0004196166992188 1.7974345684051514\n",
      "2.000354528427124 1.8025145530700684\n",
      "2.0003745555877686 1.8075546026229858\n",
      "2.000368118286133 1.8125746250152588\n",
      "2.0004935264587402 1.8175746202468872\n",
      "tensor(1.9123)\n",
      "2.0006189346313477 1.8225746154785156\n",
      "2.000955104827881 1.827534556388855\n",
      "2.001291275024414 1.8324944972991943\n",
      "2.0016274452209473 1.8374544382095337\n",
      "2.002016544342041 1.8423744440078735\n",
      "2.0024056434631348 1.8472944498062134\n",
      "2.0027947425842285 1.8522144556045532\n",
      "2.00317645072937 1.8571144342422485\n",
      "2.0033602714538574 1.8619744777679443\n",
      "2.0033841133117676 1.866794466972351\n",
      "tensor(1.8881)\n",
      "2.00325345993042 1.8715944290161133\n",
      "2.0030157566070557 1.8763744831085205\n",
      "2.0027780532836914 1.8811545372009277\n",
      "2.002540349960327 1.885934591293335\n",
      "2.002413272857666 1.8906745910644531\n",
      "2.0023081302642822 1.8953945636749268\n",
      "2.0022029876708984 1.9001145362854004\n",
      "2.0020978450775146 1.904834508895874\n",
      "2.001992702484131 1.9095544815063477\n",
      "2.0020720958709717 1.9142345190048218\n",
      "tensor(1.8656)\n",
      "2.0021514892578125 1.918914556503296\n",
      "2.002063274383545 1.9235745668411255\n",
      "2.0019352436065674 1.9282145500183105\n",
      "2.0018367767333984 1.932834506034851\n",
      "2.0017383098602295 1.9374544620513916\n",
      "2.0012259483337402 1.942014455795288\n",
      "2.0008842945098877 1.946534514427185\n",
      "2.0005719661712646 1.9510345458984375\n",
      "2.0001840591430664 1.9555145502090454\n",
      "1.9997186660766602 1.9599545001983643\n",
      "tensor(1.8446)\n",
      "1.999253273010254 1.964394450187683\n",
      "1.998958706855774 1.968814492225647\n",
      "1.998621940612793 1.9732145071029663\n",
      "1.998285174369812 1.9776145219802856\n",
      "1.997948408126831 1.982014536857605\n",
      "1.9976521730422974 1.9863945245742798\n",
      "1.9974136352539062 1.990734577178955\n",
      "1.9971410036087036 1.9950546026229858\n",
      "1.996868371963501 1.9993746280670166\n",
      "1.9964848756790161 2.0036346912384033\n",
      "tensor(1.8255)\n",
      "1.9960167407989502 2.0078747272491455\n",
      "1.995659351348877 2.0120747089385986\n",
      "1.9954818487167358 2.0162346363067627\n",
      "1.9952678680419922 2.0203347206115723\n",
      "1.9952070713043213 2.0243947505950928\n",
      "1.9951462745666504 2.0284547805786133\n",
      "1.9950854778289795 2.032514810562134\n",
      "1.9950213432312012 2.0365548133850098\n",
      "1.995236873626709 2.040534734725952\n",
      "1.9954866170883179 2.04449462890625\n",
      "tensor(1.8088)\n",
      "1.9955477714538574 2.0484347343444824\n",
      "1.995608925819397 2.052374839782715\n",
      "1.9956700801849365 2.0563149452209473\n",
      "1.9955676794052124 2.060235023498535\n",
      "1.9954652786254883 2.064155101776123\n",
      "1.9953628778457642 2.068075180053711\n",
      "1.99526047706604 2.071995258331299\n",
      "1.995158076286316 2.0759153366088867\n",
      "1.9953209161758423 2.079775333404541\n",
      "1.9954346418380737 2.083615303039551\n",
      "tensor(1.7935)\n",
      "1.9955483675003052 2.0874552726745605\n",
      "1.9956620931625366 2.0912952423095703\n",
      "1.9958370923995972 2.0951151847839355\n",
      "1.9961040019989014 2.0989151000976562\n",
      "1.9963709115982056 2.102715015411377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9966378211975098 2.1065149307250977\n",
      "1.9967783689498901 2.110294818878174\n",
      "1.9968500137329102 2.1140549182891846\n",
      "1.9969216585159302 2.1178150177001953\n",
      "1.9970358610153198 2.121535062789917\n",
      "tensor(1.7791)\n",
      "1.9971500635147095 2.1252551078796387\n",
      "1.9974042177200317 2.128955125808716\n",
      "1.997658371925354 2.132655143737793\n",
      "1.9978314638137817 2.136315107345581\n",
      "1.9980045557022095 2.139975070953369\n",
      "1.998013973236084 2.1436150074005127\n",
      "1.9980233907699585 2.1472549438476562\n",
      "1.998032808303833 2.1508948802948\n",
      "1.9980312585830688 2.154514789581299\n",
      "1.9981378316879272 2.1581146717071533\n",
      "tensor(1.7657)\n",
      "1.9982444047927856 2.161714553833008\n",
      "1.998350977897644 2.1653144359588623\n",
      "1.9984575510025024 2.168914318084717\n",
      "1.9985641241073608 2.1725142002105713\n",
      "1.9986088275909424 2.1760942935943604\n",
      "1.9985285997390747 2.179654359817505\n",
      "1.9984959363937378 2.1831743717193604\n",
      "1.9984632730484009 2.186694383621216\n",
      "1.9984999895095825 2.1901943683624268\n",
      "1.9984679222106934 2.1936542987823486\n",
      "tensor(1.7531)\n",
      "1.9984358549118042 2.1971142292022705\n",
      "1.998403787612915 2.2005741596221924\n",
      "1.9983717203140259 2.2040340900421143\n",
      "1.9983396530151367 2.207494020462036\n",
      "1.998144507408142 2.2109339237213135\n",
      "1.998206377029419 2.214334011077881\n",
      "1.998193383216858 2.2177140712738037\n",
      "1.9981803894042969 2.2210941314697266\n",
      "1.9981673955917358 2.2244741916656494\n",
      "1.9981544017791748 2.2278542518615723\n",
      "tensor(1.7414)\n",
      "1.9981046915054321 2.2312142848968506\n",
      "1.998018741607666 2.23453426361084\n",
      "1.9979327917099 2.237854242324829\n",
      "1.9978468418121338 2.2411742210388184\n",
      "1.9977608919143677 2.2444941997528076\n",
      "1.997679591178894 2.247774124145508\n",
      "1.9975982904434204 2.251054048538208\n",
      "1.9975751638412476 2.2543139457702637\n",
      "1.9975520372390747 2.2575738430023193\n",
      "1.997562289237976 2.2608139514923096\n",
      "tensor(1.7306)\n",
      "1.9975725412368774 2.2640540599823\n",
      "1.9975827932357788 2.26729416847229\n",
      "1.9975930452346802 2.2705342769622803\n",
      "1.997795581817627 2.273754358291626\n",
      "1.9979276657104492 2.276954412460327\n",
      "1.9980597496032715 2.2801544666290283\n",
      "1.9981918334960938 2.2833545207977295\n",
      "1.9982463121414185 2.286534547805786\n",
      "1.9983007907867432 2.2897145748138428\n",
      "1.9983552694320679 2.2928946018218994\n",
      "tensor(1.7203)\n",
      "1.9984097480773926 2.296074628829956\n",
      "1.9984642267227173 2.2992546558380127\n",
      "1.9987173080444336 2.302414655685425\n",
      "1.99897038936615 2.305574655532837\n",
      "1.9992234706878662 2.308734655380249\n",
      "1.9994765520095825 2.311894655227661\n",
      "1.9997345209121704 2.315014600753784\n",
      "1.9999924898147583 2.3181345462799072\n",
      "2.0002505779266357 2.3212544918060303\n",
      "2.0005085468292236 2.3243744373321533\n",
      "tensor(1.7104)\n",
      "2.000487804412842 2.3274543285369873\n",
      "2.00032901763916 2.330514430999756\n",
      "2.0002214908599854 2.33355450630188\n",
      "2.0000927448272705 2.3365745544433594\n",
      "1.9999641180038452 2.339594602584839\n",
      "1.9997706413269043 2.3425545692443848\n",
      "1.9996591806411743 2.345494508743286\n",
      "1.9995477199554443 2.3484344482421875\n",
      "1.9996147155761719 2.3513543605804443\n",
      "1.9996817111968994 2.354274272918701\n",
      "tensor(1.7014)\n",
      "1.9997512102127075 2.3571741580963135\n",
      "1.9996699094772339 2.3600542545318604\n",
      "1.9995886087417603 2.3629343509674072\n",
      "1.9996826648712158 2.365774393081665\n",
      "1.9997767210006714 2.368614435195923\n",
      "1.999870777130127 2.3714544773101807\n",
      "1.9999648332595825 2.3742945194244385\n",
      "2.000058889389038 2.3771345615386963\n",
      "2.0002667903900146 2.3799545764923096\n",
      "2.000474691390991 2.382774591445923\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label = y_noise  #  y_noise를 label로 지정\n",
    "\n",
    "# epoch 만큼 반복\n",
    "for i in range(num_epoch):\n",
    "    # 각 반복때마다 지난번에 계산했던 기울기를 0으로 초기화\n",
    "    optimizer.zero_grad() \n",
    "    # 선형회귀 모델에 x를 전달해서 해당 결과를 output에 저장\n",
    "    output = model(x)\n",
    "    \n",
    "    # |output - y_noise| 를 loss에 저장\n",
    "    loss = loss_func(output, label)\n",
    "    # loss.backward()를 호출하면 각 변수, 즉 w, b에 대한 기울기가 계산된다.\n",
    "    loss.backward()\n",
    "    \n",
    "    # optimizer 최적화 함수 step() 호출\n",
    "    # 인수로 들어갔던 model,parameters() 에서 리턴되는 변수들의 기울기에 \n",
    "    # 학습률 0.01을 곱하여 빼줌으로써 업데이트 한다.\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        \n",
    "    param_list = list(model.parameters())\n",
    "    print(param_list[0].item(), param_list[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                  #  신경망 모델들이 포함\n",
    "import torch.optim as optim            #  경사하강법 알고리즘\n",
    "import torch.nn.init as init           #  텐서에 초깃값을 주기 위해 필요한 함수들\n",
    "\n",
    "num_data = 1000\n",
    "num_epoch = 10000\n",
    "\n",
    "## input, label 설정 구간\n",
    "## input, label 설정 구간\n",
    "## input, label 설정 구간\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std = 1)\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -15, 15)\n",
    "y = (x**2) + 3\n",
    "y_noise = y + noise\n",
    "\n",
    "# Sequential 은 여러 계층을 담는 컨테이너 같은 역할이라고 생각\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(1,6),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(6,10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10,6),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(6,1)\n",
    "    )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0002)\n",
    "\n",
    "loss_array = []\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()   # \n",
    "    output = model(x)       # forward\n",
    "    loss = loss_func(output, y_noise)  # loss 계산\n",
    "    loss.backward()         # backward\n",
    "    optimizer.step()        # 경사하강법\n",
    "    loss_array.append(loss)  # loss 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

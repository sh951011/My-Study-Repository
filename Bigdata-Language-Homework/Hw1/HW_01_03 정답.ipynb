{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey~~~ there', 'hi, how are you', 'I am\\n fine, and you', ' I am good, too']\n"
     ]
    }
   ],
   "source": [
    "# 주어진 문서에서 '.','!','?' 기호만을 이용하여 문장을 분리한다.\n",
    "def split_sentence (doc):\n",
    "    sentence_list = []\n",
    "    temp_sentence = \"\"\n",
    "    for char in doc:\n",
    "        #현재 문자가 '.','!','?'중의 하나인 경우, 현재까지의 문장을\n",
    "        #리스트에 추가하고, 문장을 초기화한다.\n",
    "        if char == '.' or char == '!' or char == '?':\n",
    "            sentence_list.append(temp_sentence)\n",
    "            temp_sentence = \"\"\n",
    "        #그렇지 않은 경우, 현재 문자를 문장에 계속 추가한다.\n",
    "        else:\n",
    "            temp_sentence += char\n",
    "    return sentence_list\n",
    "\n",
    "print (split_sentence(\"hey~~~ there!hi, how are you?I am\\n fine, and you? I am good, too.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am fine\n"
     ]
    }
   ],
   "source": [
    "# 문장에서 기호를 제거하고, 하나의 공백만을 이용하여 단어를 구별한다.\n",
    "def remove_symbols (sentence):\n",
    "    #1. str.isalpha()함수를 이용하여 영문 알파벳이 아닌\n",
    "    #   모든 숫자 및 기호를 스페이스로 변환한다.\n",
    "    new_sentence = \"\"\n",
    "    for char in sentence:\n",
    "        if char.isalpha():\n",
    "            new_sentence += char\n",
    "        else:\n",
    "            new_sentence += \" \"\n",
    "    #print(new_sentence)\n",
    "\n",
    "    #2. str.join()함수를 이용하여 공백이 여러개 있는 경우,\n",
    "    #   하나로 만들어 이를 리턴한다.\n",
    "    trimmed_sentence = ' '.join(new_sentence.split())\n",
    "    return trimmed_sentence\n",
    "\n",
    "print (remove_symbols(\"I am\\n fine\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey~~~ there!hi, how are you now I am\n",
      "fine, and you? I am good, too and I have never been better too.\n"
     ]
    }
   ],
   "source": [
    "# 주어진 filepath의 파일을 오픈하여 전체 문자열을 리턴한다.\n",
    "def get_doc_str(filepath):\n",
    "    f = open(filepath,'r')\n",
    "    doc = f.readlines()\n",
    "\n",
    "    doc_str = \"\"\n",
    "    for line in doc:\n",
    "        doc_str += line\n",
    "    f.close()\n",
    "    return doc_str\n",
    "    \n",
    "print(get_doc_str(\"d1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi how\n"
     ]
    }
   ],
   "source": [
    "# 주어진 단어 리스트에서 window 구간 (begin_idx, end_idx (exclusive)) \n",
    "# 사이의 단어 리스트를 리턴한다.\n",
    "def get_window_str(d1_word_list, begin_idx, end_idx):\n",
    "    d1_window = \"\" \n",
    "    i = begin_idx\n",
    "    while i < end_idx:\n",
    "        d1_window += d1_word_list[i] + \" \"\n",
    "        i += 1\n",
    "    return d1_window.strip()\n",
    "\n",
    "print(get_window_str(['hi', 'how', 'are','you'], 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9]:  the jupyter notebook is an open source web application\n",
      "[10, 16]:  allows you to create and share\n",
      "['the jupyter notebook is an open source web application', 'allows you to create and share']\n"
     ]
    }
   ],
   "source": [
    "# 두 문장을 비교하여 최소 단어 수(min_window_size) 이상의 표절 구문 리스트를 리턴한다.\n",
    "def get_max_common(d1_sentence, d2_sentence, min_window_size):\n",
    "    d1_sentence = d1_sentence.lower()\n",
    "    d2_sentence = d2_sentence.lower()\n",
    "    \n",
    "    common_phrase_list = []\n",
    "    d1_word_list = d1_sentence.split(' ')\n",
    "    d1_window_str = \"\" #d1 문장의 연속된 구문(Phrase) 윈도우 (단어수 기준)\n",
    "    begin = 0 #연속된 구문 윈도우의 시작점   \n",
    "    \n",
    "    #시작점을 (문장의 끝 – 최소표절단어수)까지 이동하면서 표절 검사\n",
    "    while begin <= len(d1_word_list) - min_window_size:\n",
    "        # 윈도우의 끝점을 업데이트된 시작점과 최소윈도우 크기를 합한 값으로 업데이트\n",
    "        end = begin + min_window_size \n",
    "        d1_window_str = get_window_str(d1_word_list, begin, end)\n",
    "        #found_flag = False # 현재 시작점을 기준으로 표절 구문을 찾았는 지 여부를 나타내는 flag\n",
    "        \n",
    "        # 현재 시작점을 기준으로 표절 구문을 찾은 경우\n",
    "        if d2_sentence.find(d1_window_str) > -1: \n",
    "            #found_flag = True\n",
    "            # 윈도우의 끝점을 문장의 끝까지 이동하면서 현재 시작점을 기준으로 최대 표절 구문을 탐색\n",
    "            while end < len(d1_word_list):\n",
    "                d1_window_str = get_window_str(d1_word_list, begin, end)\n",
    "                if d2_sentence.find(d1_window_str) > -1:\n",
    "                    end += 1\n",
    "                else: # 현재 윈도우가 더 이상 표절 구문이 아닌 경우 break \n",
    "                    break  \n",
    "            \n",
    "            end -= 1 # 표절 구문보다 한칸 더 이동했으므로 한칸 뒤로 Back\n",
    "            \n",
    "            # 현재 윈도우를 표절 구문 리스트에 추가\n",
    "            print(\"[%d, %d]: \" %(begin,end), get_window_str(d1_word_list, begin, end))\n",
    "            common_phrase_list.append(get_window_str(d1_word_list, begin, end))\n",
    "        \n",
    "            # 표절구문을 찾은 경우, 표절구문의 끝점에서 다시 검사 시작\n",
    "            # (시작점을 단순히 1 증가시켜도, 해당 구문은 결국 현재 표절 구문의 부분 구문이기 때문) \n",
    "            begin = end\n",
    "            \n",
    "        else: # 현재 시작점을 기준으로 공통 구문을 찾지 못한 경우, 시작점을 한칸만 이동해서 다시 탐색\n",
    "            begin += 1\n",
    "    \n",
    "    return common_phrase_list\n",
    "\n",
    "print(get_max_common(\"The Jupyter Notebook is an open source web application that allows you to create and share documents\", \n",
    "                     \"The Jupyter Notebook is an open source web application which allows you to create and share documents\", 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1_doc:  hey~~~ there!hi, how are you now I am\n",
      "fine, and you? I am good, too and I have never been better too. \n",
      "\n",
      "d2_doc:  hey~~~ there!hi, how are you now and I am\n",
      "fine, and you? I am good, too and I have been better too. \n",
      "\n",
      "d1: hey there, d2: hey there\n",
      "d1: hey there, d2: hi how are you now and I am fine and you\n",
      "d1: hey there, d2: I am good too and I have been better too\n",
      "d1: hi how are you now I am fine and you, d2: hey there\n",
      "d1: hi how are you now I am fine and you, d2: hi how are you now and I am fine and you\n",
      "[0, 5]:  hi how are you now\n",
      "[5, 9]:  i am fine and\n",
      "d1: hi how are you now I am fine and you, d2: I am good too and I have been better too\n",
      "d1: I am good too and I have never been better too, d2: hey there\n",
      "d1: I am good too and I have never been better too, d2: hi how are you now and I am fine and you\n",
      "d1: I am good too and I have never been better too, d2: I am good too and I have been better too\n",
      "[0, 7]:  i am good too and i have\n",
      "[['hi how are you now', 'i am fine and'], ['i am good too and i have']]\n"
     ]
    }
   ],
   "source": [
    "# Main (간단한 표절 검사 프로그램)\n",
    "MIN_COMMON_WORDS = 4 # 표절 검사 시 기준이 되는 공통 단어 수\n",
    "\n",
    "# 1. 비교할 두 텍스트 파일로부터 전체 문자열을 가져옴 \n",
    "d1_str = get_doc_str(\"d1.txt\")\n",
    "d2_str = get_doc_str(\"d2.txt\")\n",
    "print(\"d1_doc: \", d1_str, \"\\n\")\n",
    "print(\"d2_doc: \", d2_str, \"\\n\")\n",
    "\n",
    "# 2. 마침표, 느낌표, 물음표를 기준으로 문장 단위로 Split \n",
    "d1_sentence_list = split_sentence(d1_str)\n",
    "d2_sentence_list = split_sentence(d2_str)\n",
    "\n",
    "# 3. d1 문장 리스트를 기준으로 d2 문장들을 2중 for문으로 반복하여,\n",
    "# 모든 d1, d2문장 조합을 비교하면서 최대 공통 구문을 추출\n",
    "common_phrase_list = []\n",
    "for d1_sentence in d1_sentence_list:\n",
    "    for d2_sentence in d2_sentence_list:\n",
    "        d1_sentence = remove_symbols(d1_sentence)\n",
    "        d2_sentence = remove_symbols(d2_sentence)\n",
    "        print(\"d1: %s, d2: %s\" %(d1_sentence,d2_sentence))\n",
    "        temp_list = get_max_common(d1_sentence, d2_sentence, MIN_COMMON_WORDS)\n",
    "        if len(temp_list) != 0: \n",
    "            common_phrase_list.append(temp_list)\n",
    "        \n",
    "print(common_phrase_list)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

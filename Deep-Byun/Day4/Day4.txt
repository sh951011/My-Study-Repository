
오늘은 bias를 추가해볼 시간~

y = ax에서 y = ax + b로 

1시간 공부하면 1점 2시간 공부하면 2점이 아니라, 교수님이 착하셔서 기본 점수를 주셨다 !!
=> 전체에게 +b !!

근데 이 b도 학습의 대상이 된다 !!


y = wx + b일때 w와 b는 서로 다르게 업데이트 된다고 생각할 수 있는데, 어느 정도는 맞는 말이지만,
한 번의 루프가 아닌 다음 루프까지 생각해보면 w나 b가 학습이 느리다면 다음 추론이 망할 것이기 때문에 
서로에게 영향을 끼친다고 생각하면 된다.'

같은 데이터셋을 쓰더라도 bias에 따라서 학습의 속도가 달라질 수 있다는 것이다.

w와 bias의 gradient를 계산해보면 w는 입력 데이터 x가 포함되어 있지만, bias는 입력 데이터 x가 포함되어 있지 않다.
즉, w는 입력 데이터 x에 의해 gradient가 영향을 받지만, bias는 입력 데이터 x는 영향을 받지 않음을 알 수 있다. ★★★★★

bias는 데이터의 크기에 영향을 거의 받지 않지만 하지만 데이터 x의 웨이트인 w는 어마어마하게 영향을 받는다 !!

std는 0~1정도로 맞춰주는게 의미가 있다 !! 너무 크면 학습이 안 된다!!

그리고 평균도 0으로 맞춰주는 것이 좋다 !!
그래서 '행복코딩' 팀이 mfcc를 뽑을 때 피쳐 평균을 0으로 맞춰준 것일 수도 있다!
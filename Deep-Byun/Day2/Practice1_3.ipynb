{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Practice.1-3\n",
    "## Forward and Backward Propagation with $y = \\theta x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 Practice1-3에서는 Practice1-2에서 다뤘던 cost를 통한 parameter update에서 for loop을 사용하지 않고 np.dot()을 이용한 Vectorization으로 코드를 작성해본다.\n",
    "\n",
    "먼저 우리가 가지고 있는 data의 shape은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,) (5,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = np.array([1, 2, 3, 4, 5])\n",
    "y_data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice1-2에서 $l^{(1)}, l^{(2)}, l^{(3)}, l^{(4)}, l^{(5)}$를 따로 구해 cost를 구했다면 Practice1-3에서는 이 loss들을 vector로 만든 L로 구해서 cost를 구할 것이다.\n",
    "\n",
    "위의 표시와 같이 vectorized가 되지 않은 값들을 소문자, vectorization이 된 값들을 대분자로 나타내면 다음과 같은 표기가 가능하다.\n",
    "\n",
    "$ X = $ [ $x^{(1)},\\; x^{(2)},\\; x^{(3)},\\; x^{(4)},\\; x^{(5)} $ ]\n",
    "\n",
    "$ Y = $ [ $y^{(1)},\\; y^{(2)},\\; y^{(3)},\\; y^{(4)},\\; y^{(5)} $ ]\n",
    "\n",
    "$ Z_{1} = $ [ $z_{1}^{(1)},\\; z_{1}^{(2)},\\; z_{1}^{(3)},\\; z_{1}^{(4)},\\; z_{1}^{(5)} $ ]\n",
    "\n",
    "$ Z_{2} = $ [ $z_{2}^{(1)},\\; z_{2}^{(2)},\\; z_{2}^{(3)},\\; z_{2}^{(4)},\\; z_{2}^{(5)} $ ]\n",
    "\n",
    "$ L = $ [ $l^{(1)},\\; l^{(2)},\\; l^{(3)},\\; l^{(4)},\\; l^{(5)} $ ]\n",
    "\n",
    "$ dL = $ [ $dl^{(1)},\\; dl^{(2)},\\; dl^{(3)},\\; dl^{(4)},\\; dl^{(5)} $ ]\n",
    "\n",
    "$ dZ_{2} = $ [ $dz_{2}^{(1)},\\; dz_{2}^{(2)},\\; dz_{2}^{(3)},\\; dz_{2}^{(4)},\\; dz_{2}^{(5)} $ ]\n",
    "\n",
    "$ dZ_{1} = $ [ $dz_{1}^{(1)},\\; dz_{1}^{(2)},\\; dz_{1}^{(3)},\\; dz_{1}^{(4)},\\; dz_{1}^{(5)} $ ]\n",
    "\n",
    "NumPy의 연산특징을 이용해 1 epoch에 대한 위의 값들을 차례대로 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Your Code(Forward Propagation) #####\n",
    "\n",
    "\n",
    "##### Your Code(Forward Propagation) #####\n",
    "    \n",
    "##### Your Code(Backward Propagation) #####\n",
    "\n",
    "\n",
    "##### Your Code(Backward Propagation) #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 이용하여 Practice1-2에서 했던 learning process를 vectorization된 형태로 구현하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "\n",
    "z1_node = mul_node()\n",
    "z2_node = minus_node()\n",
    "z3_node = square_node()\n",
    "c_node = cost_node()\n",
    "\n",
    "loss_list = []\n",
    "theta_list = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    gradient_np = np.empty(0)\n",
    "    theta_np = np.empty(0)\n",
    "    \n",
    "    for i in range(len(x_data)): \n",
    "        ##### Your Code(Forward Propagation) #####\n",
    "\n",
    "\n",
    "        ##### Your Code(Forward Propagation) #####\n",
    "        gradient_np = np.append(gradient_np, np.array([z3]))\n",
    "        \n",
    "    cost = c_node.forward(gradient_np)\n",
    "    loss_list.append(cost)\n",
    "    dz = c_node.backward()\n",
    "    \n",
    "    for i in range(len(x_data)):\n",
    "        ##### Your Code(Forward Propagation) #####\n",
    "\n",
    "\n",
    "        ##### Your Code(Forward Propagation) #####\n",
    "        theta_np = np.append(theta_np, np.array([dtheta]))\n",
    "    theta = theta - lr*np.mean(theta_np)\n",
    "    theta_list.append(theta)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.plot(loss_list)\n",
    "ax.set_title(\"loss\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.plot(theta_list)\n",
    "ax.set_title(r\"$\\theta$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
